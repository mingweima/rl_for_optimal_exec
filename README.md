# Reinforcement Learning for Optimal Execution 

This is the repo that researches RL for optimal trade execution. We design RL methods that learn from L>10 limit order book (LOB) data and compare our result with the Almgren-Chriss benchmark method in [Almgren & Chriss (1999)](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwi2-LKP-qnmAhW-RBUIHdapB80QFjAAegQIBRAC&url=https%3A%2F%2Fwww.math.nyu.edu%2Ffaculty%2Fchriss%2Foptliq_f.pdf&usg=AOvVaw2zXBvgn3vwTcEv5__jTDy).

## The *Gym Trading* Envirnment 

TODO: Introduce the Gym Trading Env. Cite ABIDES.

### 1. Installing *Gym Trading*

To install the gym trading environment , run `pip install -e .`

### 2. Load LOB Data with *Gym Trading*

TODO: How to load data

### 3. Customize Observations and Rewards with *Gym Trading*

TODO: How to choose your own observations and reward functions. 

## Reinforcement Learning Algorithms 

TODO: Introduce the Algos we use. Cite the original papers and 294-112.

## New Methods

TODO: Outline some new methods we want to experiment with. 

